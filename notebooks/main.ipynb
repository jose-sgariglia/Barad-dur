{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library & Constants\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Options\n",
    "\n",
    "XGB_FEATER_SELECTION = True\n",
    "BINARY_CLASSIFICATION = True\n",
    "\n",
    "# Paths\n",
    "\n",
    "DATASET_DIR = '../data'\n",
    "MODEL_DIR = '../models'\n",
    "\n",
    "# Datsets Info\n",
    "\n",
    "MAPPING_BINARY_LABELS = ['Benign', 'Malicious']\n",
    "BINARY_LABELS = {\n",
    "    0: 'Benign',\n",
    "    1: 'Malicious'\n",
    "}\n",
    "\n",
    "MAPPING_MULTICLASS_LABELS = {\n",
    "    0: 'Benign',\n",
    "    1: 'Web Attack',\n",
    "    2: 'DoS Attack',\n",
    "    3: 'Network Attack',\n",
    "    4: 'Botnet',\n",
    "    5: 'Service Attack'\n",
    "}\n",
    "MULTICLASS_LABELS = {\n",
    "    0: ['Benign'],\n",
    "    1: [\"Web_XSS\", \"Web_SQL_Injection\", \"Web_Brute_Force\"],                                 # Web Attack\n",
    "    2: [\"DoS_Slowhttptest\", \"DoS_GoldenEye\", \"DDoS_LOIT\", \"DoS_Hulk\", \"DoS_Slowloris\"],     # DoS Attack\n",
    "    3: [\"Port_Scan\", \"Heartbleed\"],                                                         # Network Attack        \n",
    "    4: [\"Botnet_ARES\"],                                                                     # Botnet\n",
    "    5: [\"SSH-Patator\", \"FTP-Patator\"]                                                       # Service Attack                                           \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Prima di procedere con la modellazione del dataset e alla creazione del modello, procediamo con il capire come i dati sono strutturati, cosa rappresentano e quali modifiche rapportare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "def load_data(datasets_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all datasets from a directory into a single DataFrame\n",
    "\n",
    "    :param str datasets_dir: directory containing the datasets\n",
    "    :return: pd.DataFrame containing all datasets\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    for file in os.listdir(datasets_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            data.append(pd.read_csv(os.path.join(datasets_dir, file)))\n",
    "\n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = load_data(DATASET_DIR)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniziamo l’analisi osservando la quantità di dati disponibili nel nostro dataset, BCCC-CIC-IDS2017, che comprende un totale impressionante di 2.438.052 record. Questi dati sono stati generati utilizzando NTLFlowLyzer, in contrasto con la versione precedente del dataset (CIC-IDS2017), che aveva invece adottato lo strumento CICFlowMeter per l'estrazione.\n",
    "\n",
    "Per approfondire e comprendere meglio i dati a disposizione, esploriamoli graficamente per analizzarne la distribuzione e identificarne eventuali pattern significativi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Data\n",
    "\n",
    "def plot_attacks_distribution(target: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generates a bar chart to visualize the distribution of attack labels in the given dataset.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset containing the 'label' column to generate the pie chart from.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.style.context('dark_background'):\n",
    "        attack_data = dataset[~dataset['label'].isin(MAPPING_BINARY_LABELS)]['label'].value_counts()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(26, 10))\n",
    "        ax.bar(attack_data.index, attack_data.values, width=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def plot_distribution(dataset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generates a pie chart to visualize the distribution of 'Benign' and 'Attack' labels in the given dataset.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset containing the 'label' column to generate the pie chart from.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.style.context('dark_background'):\n",
    "        data = {\n",
    "            'Benign': dataset['label'].isin(MAPPING_BINARY_LABELS).sum(),\n",
    "            'Malicius': dataset[~dataset['label'].isin(MAPPING_BINARY_LABELS)]['label'].value_counts().sum()\n",
    "        }\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.pie(data.values(), labels=data.keys(), autopct='%1.1f%%', startangle=140, colors=['#66b3ff', '#D4FCC3'])\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_distribution(dataset)\n",
    "    plot_attacks_distribution(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dall'analisi dei dati emergono due osservazioni principali:\n",
    "1. Il traffico normale è significativamente più rappresentato rispetto al traffico malevolo. Questo squilibrio può essere affrontato in modo intuitivo attraverso l’applicazione di tecniche di __undersampling__ sui dati relativi al traffico normale.\n",
    "2. La distribuzione dei dati degli attacchi non è uniforme.\n",
    "\n",
    "Concentrandoci sul secondo punto, l’alto sbilanciamento dei dati può influire negativamente sulle prestazioni del modello, aumentando il rischio di errori di predizione, soprattutto per le classi meno rappresentate. Per mitigare questo problema, è possibile adottare diversi approcci, ognuno con vantaggi e svantaggi:\n",
    "\n",
    "- Escludere attacchi con pochi dati\n",
    "- Applicare tecniche di undersampling e oversampling(undersampling).\n",
    "- Focalizzarsi su un singolo tipo di attacco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Per semplicità, procediamo con l'under sampling ed escludiamo il problema della distribuzione degli attacchi etichettando i dati solo con \"Benign\" e \"Malicious\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "from typing import List\n",
    "\n",
    "def clean_data(dataset: pd.DataFrame, columns_to_remove: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans the given dataset.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to clean.\n",
    "    :param List[str] columns_to_remove: The columns to remove from the dataset.\n",
    "    :return: The cleaned dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.drop_duplicates()\n",
    "\n",
    "    float_cols = dataset.select_dtypes(include=['float']).columns\n",
    "    dataset[float_cols] = dataset[float_cols].round(4)\n",
    "\n",
    "    dataset = dataset.drop(columns=columns_to_remove)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Before cleaning:\")\n",
    "    print(dataset.info())\n",
    "\n",
    "    columns_to_remove = [\"flow_id\", \"src_ip\", \"dst_ip\", \"src_port\", \"timestamp\"]\n",
    "    dataset = clean_data(dataset, columns_to_remove)\n",
    "\n",
    "    print(\"\\nAfter cleaning:\")\n",
    "    print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Labeling\n",
    "\n",
    "def binary_labeling(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the 'label' column in the given dataset to binary labels.\n",
    "    0 for benign and 1 for malicious.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to convert.\n",
    "    :return: The dataset with binary labels.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset['label'] = dataset['label'].apply(lambda x: 0 if x in MAPPING_BINARY_LABELS else 1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def multiclass_labeling(dataset: pd.DataFrame, mapping_label: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the 'label' column in the given dataset to multiclass labels.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to convert.\n",
    "    :param dict mapping_label: The mapping of labels to convert to.\n",
    "    :return: The dataset with multiclass labels.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset['label'] = dataset['label'].map(mapping_label)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Before {\"Binary\" if BINARY_CLASSIFICATION else 'Multiclass'} labeling:\")\n",
    "    print(dataset['label'].value_counts())\n",
    "\n",
    "    if BINARY_CLASSIFICATION:\n",
    "        dataset = binary_labeling(dataset)\n",
    "    else:\n",
    "        group_map = {attack: group for group, attacks in MULTICLASS_LABELS.items() for attack in attacks}\n",
    "        dataset = multiclass_labeling(dataset, group_map)\n",
    "\n",
    "    print(f\"\\nAfter {\"Binary\" if BINARY_CLASSIFICATION else 'Multiclass'} labeling:\")\n",
    "    print(f\"\\t[Mapping] {BINARY_LABELS if BINARY_CLASSIFICATION else MAPPING_MULTICLASS_LABELS}\")\n",
    "    print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Features and Labels\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def extract_feature_and_target(dataset: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Extracts the feature and target columns from the given dataset.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to extract the feature and target columns from.\n",
    "    :return: The feature and target columns.\n",
    "    \"\"\"\n",
    "\n",
    "    return dataset.drop(columns=['label']), dataset['label']\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, y = extract_feature_and_target(dataset)\n",
    "\n",
    "    del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting before Data Balancing\n",
    "\n",
    "def plot_attacks_distribution(target: pd.Series, mapping: list):\n",
    "    \"\"\"\n",
    "    Generates a bar chart to visualize the distribution of attack labels in the given dataset.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset containing the 'label' column to generate the pie chart from.\n",
    "    :param dict mapping: The mapping of labels to convert to.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.style.context('dark_background'):\n",
    "        attack_data = target.value_counts()\n",
    "        attack_data.index = attack_data.index.map(mapping)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(26, 10))\n",
    "        ax.bar(attack_data.index, attack_data.values, width=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def plot_distribution(target: pd.Series, mapping: dict):\n",
    "    \"\"\"\n",
    "    Generates a pie chart to visualize the distribution of 'Benign' and 'Attack' labels in the given dataset.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset containing the 'label' column to generate the pie chart from.\n",
    "    :param dict mapping: The mapping of labels to convert to.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.style.context('dark_background'):\n",
    "        data = target.value_counts()\n",
    "        data.index = data.index.map(mapping)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.pie(data.values, labels=data.index, autopct='%1.1f%%', startangle=140, colors=['#66b3ff', '#D4FCC3'])\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    if BINARY_CLASSIFICATION:\n",
    "        plot_distribution(y, BINARY_LABELS)\n",
    "    else:\n",
    "        plot_attacks_distribution(y, MAPPING_MULTICLASS_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Balancing\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def balance_data_binary(dataset: pd.DataFrame, target: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Balances the given dataset using RandomUnderSampler.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to balance.\n",
    "    :param pd.Series target: The target column to balance.\n",
    "    :return: The balanced dataset and target.\n",
    "    \"\"\"\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(dataset, target)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, y = balance_data_binary(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting after Data Balancing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if BINARY_CLASSIFICATION:\n",
    "        plot_distribution(y, BINARY_LABELS)\n",
    "    else:\n",
    "        plot_attacks_distribution(y, MAPPING_MULTICLASS_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def one_hot_encoding_dataset(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies one-hot encoding to all columns of type \"object\" in a pandas DataFrame.\n",
    "\n",
    "    :param pd.DataFrame dataset: The DataFrame to apply one-hot encoding to.\n",
    "    :return: The DataFrame with one-hot encoding applied.\n",
    "    \"\"\"\n",
    "\n",
    "    object_columns = dataset.select_dtypes(include=['object']).columns\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    encoded_array = encoder.fit_transform(dataset[object_columns])\n",
    "    encoded_columns = encoder.get_feature_names_out(object_columns)\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns)\n",
    "    dataset = pd.concat(\n",
    "        [dataset.drop(columns=object_columns).reset_index(drop=True), encoded_df.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = one_hot_encoding_dataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def normalize_data(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalizes the given dataset using Min-Max scaling.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to normalize.\n",
    "    :return: The normalized dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_array = scaler.fit_transform(dataset)\n",
    "\n",
    "    normalized_df = pd.DataFrame(normalized_array, columns=dataset.columns, index=dataset.index)\n",
    "    return normalized_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = normalize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "def select_features(dataset: pd.DataFrame, target: pd.Series, binary_classification: bool, threshold: float = 0.01, using_xgb: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Selects the most important features from the given dataset using a tree-based model.\n",
    "\n",
    "    :param pd.DataFrame dataset: The dataset to select features from.\n",
    "    :param pd.Series target: The target column.\n",
    "    :param bool binary_classification: Whether the task is binary classification or not.\n",
    "    :param float threshold: The threshold to use for feature selection.\n",
    "    :param bool using_xgb: Whether to use XGBoost for feature selection or not.\n",
    "    :return: The selected features.\n",
    "    \"\"\"\n",
    "\n",
    "    if using_xgb:\n",
    "        if binary_classification:\n",
    "            clf = XGBClassifier(eval_metric='logloss', random_state=42, objective='binary:logistic')\n",
    "        else:\n",
    "            clf = XGBClassifier(eval_metric='mlogloss', random_state=42, objective='multi:softmax')\n",
    "    else:\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    clf.fit(dataset, target)\n",
    "    feature_importances = clf.feature_importances_\n",
    "    sfm = SelectFromModel(clf, threshold=threshold, prefit=True)\n",
    "    selected_features = dataset.columns[sfm.get_support()]\n",
    "    feature_scores = {feature: importance for feature, importance in zip(dataset.columns, feature_importances) if importance >= threshold}\n",
    "\n",
    "    return selected_features, feature_scores\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    features_name, features_scored = select_features(X, y, BINARY_CLASSIFICATION, using_xgb=XGB_FEATER_SELECTION)\n",
    "    num_features = len(features_name)\n",
    "\n",
    "    print(f\"Selected features with threshold >= 0.01:\")\n",
    "    for feature, score in sorted(features_scored.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"\\t{feature}\\t{score:.4f}\")\n",
    "\n",
    "    X = X[features_name]\n",
    "    print(\"Dataset after Feature Selection:\")\n",
    "    print(X.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "Procederemo con lo sviluppo del modello facendo riferimento progetto github [_\"Efficient-CNN-BiLSTMs\"_](https://github.com/jayxsinha/Efficient-CNN-BiLSTM-for-Network-IDS/) per la sua struttura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# The neural network model works only wiht numpy arrays, so we need to convert the dataframes to numpy arrays \n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Moreover, the neural network model has a specific input shape, so we need to reshape the data\n",
    "X_train = X_train.reshape((-1, num_features, 1))\n",
    "X_test = X_test.reshape((-1, num_features, 1))\n",
    "\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Desing\n",
    "\n",
    "I layer di questo modello sono i seguenti:\n",
    "- CNN: Utile per apprendere le relazioni più nascoste tra le feature\n",
    "- 2 BiLSTMs: Per poter capire come le feature hanno effetto su lungo raggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Design\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Bidirectional, LSTM, Reshape, Dropout, Dense, Activation\n",
    "\n",
    "def build_model(input_shape=(122, 1)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1D Convolutional layer\n",
    "    model.add(Convolution1D(64, kernel_size=input_shape[0], padding=\"same\", activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Bidirectional LSTM layer\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "    \n",
    "    # Reshape layer\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Second Bidirectional LSTM layer\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    \n",
    "    # Dropout layer\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Dense output layer with sigmoid activation\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = build_model(input_shape=(num_features, 1))\n",
    "\n",
    "    print(\"Model Summary:\")\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_model(model, X_train, y_train, batch_size=32, epochs=10, patience=3, validation_data=None):\n",
    "    \"\"\"\n",
    "    Trains the given model with early stopping.\n",
    "\n",
    "    :param keras.models.Sequential model: The model to train.\n",
    "    :param np.ndarray X_train: The training features.\n",
    "    :param np.ndarray y_train: The training target.\n",
    "    :param int batch_size: The batch size for training.\n",
    "    :param int epochs: The number of epochs for training.\n",
    "    :param Tuple[np.ndarray, np.ndarray] validation_data: The validation features and target.\n",
    "    :return: The trained model and training history.\n",
    "    \"\"\"\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model, history = train_model(model, X_train, y_train, epochs=100, patience=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Evaluation\n",
    "\n",
    "def plot_training_metrics(history) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics from the history object.\n",
    "\n",
    "    :param history: The training history object.\n",
    "    :return: Matplotlib figure of the training metrics.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    train_acc = history.history.get('accuracy', None)\n",
    "    val_acc = history.history.get('val_accuracy', None)\n",
    "    if train_acc and val_acc:\n",
    "        ax[0].plot(train_acc, label='Training Accuracy', marker='o')\n",
    "        ax[0].plot(val_acc, label='Validation Accuracy', marker='x')\n",
    "        ax[0].set_title('Training and Validation Accuracy per Epoch')\n",
    "        ax[0].set_xlabel('Epochs')\n",
    "        ax[0].set_ylabel('Accuracy')\n",
    "        ax[0].legend()\n",
    "        ax[0].grid(True)\n",
    "\n",
    "    # Loss Plot\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', None)\n",
    "    ax[1].plot(train_loss, label='Training Loss', marker='o')\n",
    "    if val_loss:\n",
    "        ax[1].plot(val_loss, label='Validation Loss', marker='x')\n",
    "    ax[1].set_title('Training and Validation Loss per Epoch')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_history = plot_training_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_evaluation_metrics(y_test, y_pred, y_pred_probs, is_binary=True, target_mapping=None) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix and ROC curve for the given predictions.\n",
    "\n",
    "    :param np.ndarray y_test: The true target labels.\n",
    "    :param np.ndarray y_pred: The predicted target labels.\n",
    "    :param np.ndarray y_pred_probs: The predicted target probabilities.\n",
    "    :param bool is_binary: Whether the classification is binary or multiclass.\n",
    "    :param dict target_mapping: The mapping of target labels.\n",
    "    :return: Matplotlib figure of the evaluation metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_binary:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "    if target_mapping:\n",
    "        labels = [target_mapping.get(label, label) for label in np.unique(y_test)]\n",
    "    else:\n",
    "        labels = np.unique(y_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=labels, yticklabels=labels, \n",
    "                ax=axes[0] if is_binary else ax)\n",
    "    \n",
    "    if is_binary:\n",
    "        axes[0].set_xlabel(\"Predicted\")\n",
    "        axes[0].set_ylabel(\"Original\")\n",
    "        axes[0].set_title(\"Confusion Matrix\")\n",
    "    else:\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Original\")\n",
    "        ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    if is_binary:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        axes[1].plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\", color=\"darkorange\")\n",
    "        axes[1].plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "        axes[1].set_xlabel(\"False Positive Rate\")\n",
    "        axes[1].set_ylabel(\"True Positive Rate\")\n",
    "        axes[1].set_title(\"Receiver Operating Characteristic\")\n",
    "        axes[1].legend(loc=\"lower right\")\n",
    "        \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, is_binary=True, target_mapping=None) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Evaluates the given model using the test data and plots the evaluation metrics.\n",
    "\n",
    "    :param keras.models.Sequential model: The trained model to evaluate.\n",
    "    :param np.ndarray X_test: The test features.\n",
    "    :param np.ndarray y_test: The test target.\n",
    "    :param bool is_binary: Whether the classification is binary or multiclass.\n",
    "    :param dict target_mapping: The mapping of target labels.\n",
    "    :return: Matplotlib figure of the evaluation metrics.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if is_binary:\n",
    "        y_pred_probs = model.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred_probs = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score (Weighted): {f1:.2f}\")\n",
    "\n",
    "    return plot_evaluation_metrics(y_test, y_pred, y_pred_probs, is_binary, target_mapping)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_cm_and_roc = evaluate_model(model, X_test, y_test, is_binary=BINARY_CLASSIFICATION, target_mapping=BINARY_LABELS if BINARY_CLASSIFICATION else MAPPING_MULTICLASS_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import json\n",
    "\n",
    "def save_model(model, features: list, mapping_used: list, plots: dict, path: str = \"../models\"):\n",
    "    \"\"\"\n",
    "    Saves the given model, features, and plots to the specified path.\n",
    "\n",
    "    :param keras.models.Sequential model: The model to save.\n",
    "    :param list features: The list of features used by the model.\n",
    "    :param dict plots: A dictionary of plots to save.\n",
    "    :param str path: The path to save the model to.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    version = len(os.listdir(path)) + 1\n",
    "    model_dir = os.path.join(path, f\"v{version}\")\n",
    "\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(os.path.join(model_dir, \"model.keras\"))\n",
    "\n",
    "    # Save the features as a JSON file\n",
    "    with open(os.path.join(model_dir, \"features.json\"), \"w\") as f:\n",
    "        json.dump(features, f, indent=4)\n",
    "\n",
    "    # Save the mapping used as a JSON file\n",
    "    with open(os.path.join(model_dir, \"mapping.json\"), \"w\") as f:\n",
    "        json.dump(mapping_used, f, indent=4)\n",
    "\n",
    "    # Save the plots\n",
    "    for name, plot in plots.items():\n",
    "        plot.savefig(os.path.join(model_dir, f\"{name}.png\"))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    figure_dict = {\n",
    "        \"plot_cm_and_roc\": plot_cm_and_roc,\n",
    "        \"plot_history\": plot_history    \n",
    "    }\n",
    "\n",
    "    save_model(model, features_name, BINARY_LABELS if BINARY_CLASSIFICATION else MAPPING_MULTICLASS_LABELS, figure_dict, MODEL_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
